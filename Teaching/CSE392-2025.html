<html><head>
		<meta http-equiv="content-type" content="text/html; charset=windows-1252">
		<title>CSE 392: Matrix and Tensor Algorithms for Data, Spring 2025</title>
	</head>

<body>

<p></p>
<hr>
<p></p>

<h1> 
	University of Texas at Austin, Spring 2025
	<br>	<br>
CSE 392: Matrix and Tensor Algorithms for Data
</h1>

<p></p>
<hr>
<p></p>

<h3>Instructor</h3> 
<a href="https://shashankaubaru.github.io/"><b>Shashanka Ubaru</b> </a> 
<li>Email: shashanka.ubaru(at)austin.utexas.edu</li>
<li>Office hours:  Mondays 1:30pm - 2:30pm.</li>
<li>Location: POB: 3.134.</li> 

<p></p>


<b>Class time and Location:</b>
<li>Mondays and Wednesdays, 11:00am - 12:30pm, GDC 2.402.</li>

<p></p>
<hr>
<p></p>


<h3>Course description</h3>
Advances in modern technologies have resulted in huge volumes of data being generated in several scientific, industrial, and social domains. With ever increasing size of data comes the necessity to develop fast and scalable machine learning and data algorithms to process and analyze them. In this course, we study the mathematical foundations of large-scale data processing, with focus on  designing algorithms and learning to (theoretically) analyze them. We explore randomized numerical linear algebra (sketching and sampling) and tensor methods for processing and analyzing large-scale multidimensional data, graphs, and data-streams. We will also have presentations on the linear algebra concepts of quantum computing.
<p></p>

<b>Prerequisites:</b> 
The minimum requirements for the course are basics concepts of probability, algorithms, and linear algebra. Knowledge and experience with machine learning algorithms will be helpful. For the course, we will rely most heavily on probability, linear and tensor algebra, but we will also learn few concepts related to approximation theory, high dimensional geometry, and  quantum computing. The course will involve rigorous theoretical analyses and some programming (practical implementation and applications). 

<p></p>

<b>Programming language:</b> The programming languages for the course will be <i>Matlab</i> and/or <i>Python</i>.

<p></p>

<b>Syllabus:</b> <a href="2025/Course_syllabus.pdf">PDF</a>

<p></p>

<p></p>
<hr>
<p></p>

<h3>Grading</h3> 
Grading is based on problem sets,  project/presentation, and class participation. There will be no exams.  The breakdown is as follows:

<ul>
	
  
	<li>
	<i>Assignments - 50%:</i> Four assignments including problem sets and programming exercises.
	</li>
  
	<li>
	<i>Class project - 40%:</i>  There will be a project proposal submission (before Spring break), and a final presentation of the projects during the last week of the semester, along with a final report submission.
	</li>
	
	<li>
	<i>Participation- 10%:</i> Participation in the class</a>.
	</li>
  
  </ul>

 Assignments are to be submitted through Canvas, and should be individual work. You are allowed to discuss the problems with your
classmates and to work collaboratively. The preferred format is to upload your work as a single PDF, preferably typewritten (using LaTeX,
Markdown, or some other mathematical formatting program).
In general, late assignments will not receive credit.

<!--
%-----------------------------------------------------------------------
-->

<p></p>
<hr>
<p></p>

<h3> Lectures</h3>


<table cellpadding="2" cellspacing="2" border="1" style="text-align: left;">
	<tbody>
	  <tr>
		<td style="vertical-align: top;width:220px"><span style="font-weight:bold;">Dates</span><br>
		</td>
		<td style="vertical-align: top;width:630px"><span style="font-weight:bold;">Topics covered</span><br>
		</td>
		<td style="vertical-align: top;width:220px"><span style="font-weight:bold;">Slides</span><br>
		</td>

	  </tr>
  
	  <tr>
		<td style="vertical-align: top;">
		Week 1 (Jan 13, 2025)
		</td>
		<td style="vertical-align: top;">
		Lecture 1: Vector spaces, matrices, and norms.
		<br>
		Lecture 2: Probability review, concentration of measure.
		</td>
		<td style="vertical-align: top;">
		
		</td>
	  </tr>
  
  
  
	</tbody>
  </table>



  <p></p>
  <hr>
  <p></p>
  
  <h3> Problem Sets</h3>


<p></p>
<hr>
<p></p>

<h3> Resources</h3>

<ul>
	<li> Dr. David Woodruff's monograph <a href="https://arxiv.org/abs/1411.4357">Sketching as a Tool for Numerical Linear Algebra</a>. 
</li>
<li> Dr. Tamara Kolda's review paper on <a href="https://www.kolda.net/publication/TensorReview.pdf">Tensor Decompositions and	Applications</a>. 
</li>
  <li> Dr. Yousef Saad's textbook <a href="http://www.cs.umn.edu/~saad/eig_book_2ndEd.pdf">Numerical Methods for Large
Eigenvalue Problems</a>. 
</li>
</ul>
<p></p>
<hr>
<p></p>




<script>if(window.parent==window){(function(i,s,o,g,r,a,m){i["GoogleAnalyticsObject"]=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,"script","//www.google-analytics.com/analytics.js","ga");ga("create","G-6FTL175Z2R","auto",{"siteSpeedSampleRate":100});ga("send","pageview");}</script>
</body></html>
